# (PART) 統計推斷 Inference {-}

# 統計推斷的概念

## 人羣與樣本 (population and sample)

討論樣本時，需考慮下面幾個問題：

1. 樣本是否具有代表性？
2. 人羣被準確定義了嗎？
3. 我們感興趣的“人羣”是否可以是無限大（多）的？
4. 我們研究的樣本，是僅僅用來觀察，亦或是計劃對之進行某種干預呢？
5. 我們從所有可能的人羣中抽樣了嗎？


## 樣本和統計量 (sample and statistic)

通常我們在進行實驗或觀察時只是獲得了樣本的數據。而希望從樣本數據去推斷 (inference) 總體（或人羣）的一些特徵。我們也許只是想用樣本的平均值來估計整體人羣的某個特徵的平均值。不管是何種估計和推斷，都是基於對樣本數據的計算，從樣本中獲得想要推斷總體的**統計量 (statistics)**。我們用已知樣本去推斷未知總體的過程就叫做**估計 (estimate)**。這個想要被推斷的總體或人羣的值，被叫做**參數 (parameter)**，常常使用希臘字母來標記。用來估計總體或人羣的，從樣本數據計算得來的統計量，叫做**估計量 (estimator)**。

所有的統計量，都有**樣本分佈 (sampling distributions，意爲重複無限次取樣後獲得的無限次統計量的分佈)**。推斷的過程歸納如下：

1. 從總體或人羣中抽樣 (樣本量 $n$)
2. 計算這個樣本的合適統計量，從而用於估計它在整體或人羣中的值。
3. 我們還需要決定計算獲得的統計量的樣本分佈（假定會抽樣無數次）。
4. 一旦可以精確地確認樣本分佈，我們就可以定量地計算出使用步驟2中獲得的統計量估計總體或人羣的參數時的準確度。

## 估計 Estimation

從樣本的均值，推斷總體或人羣的均值是一種估計。我們的目的是，從已知樣本中計算一個儘可能接近那個未知的總體或人羣參數的值。一個估計量有兩個與生俱來的性質 (properties)：1) 偏倚 (bias); 2) 精確度 (precision)。這兩個性質都可以從樣本分佈和估計量獲得。

1. 偏倚： 偏倚簡單說就是樣本分佈的均值，也就是我們從樣本中計算獲得的估計量，和我們想要拿它來估計的總體或人羣的參數之間的差距。(The bias is the difference between the mean of the sampling distribution -- the expected or average value of the estimator -- and the population parameter being estimated.) 一個小的偏倚，確保了我們從樣本中計算獲得的估計值（假設我們抽樣無數次，計算無數個樣本估計值）**均勻地**分佈在總體或人羣參數的左右兩邊。偏倚本身並不是太大的問題，但是假如樣本量增加，偏倚依然存在（估計量不一致, inconsistent），那常常意味着是抽樣過程出現了問題。例如：<br>用簡單隨機抽樣法獲得的樣本均值，就是總體或人羣均值的無偏估計 (unbiased estimator)。如果抽樣時由於某些主觀客觀的原因導致較小的樣本很少被抽樣（抽樣過程出了問題，脫離了簡單隨機抽樣原則），那麼此時得到的樣本均值就會是一個過高的估計值 (upward biased estimator)。

2. 精確度：估計值的精確度可以通過樣本分佈的方差或標準差來評價（簡單說是樣本分佈的方差越低，波動越小，精確度越高）。樣本分佈的標準差被定義爲估計值的標準誤。假如估計量是樣本均值，那麼樣本分佈的標準差（估計量的標準誤）和樣本數據之間有如下的關係：

$$true\; stantdard\; error\;of\;the\;mean  = \frac{true\;standard\;deviation}{\sqrt{sample\;size}}$$


在一些簡單的情況下，通常估計值的選用不言自明（例如均值，或者百分比）。但是在複雜的情況下，我們可能可以有多個不同類型的估計量可以選擇，他們也常常各有利弊，需要我們做出取捨。

## 信賴區間  confidence intervals

從樣本中計算估計量獲得的一個估計值，只是一個**點估計 (point estimate)**。對比之下，信賴區間就是一個對這個點估計的精確度的體現。信賴區間越窄，說明我們對於總體或人羣的參數的可能取值的範圍估計越精確。

信賴區間通常是成對成對的出現的，即有上限和下限。這樣的一對從樣本數據中計算得來的統計量，同樣也是有樣本分佈的。**每次我們重新從總體或人羣中抽樣，計算獲得的信賴區間都不同，這些信賴區間就組成了信賴區間的樣本分佈。總體和人羣的參數落在這些信賴區間範圍內的概率，就是我們常說的信賴區間的水平（$95\%$）。** 常用的這個概率值就是 $95\%, 90\%, 99\%$。

當從樣本數據計算獲得的估計量的信賴區間很寬，說明了這個收集來的數據提供了很少的參數信息，導致估計變得很不精確。




~~看到這裏的都是好漢一條啊！ 我不知道你暈了麼有，反正我是已經暈了。。。~~


# 估計和精確度 Estimation and Precision

## 估計量和他們的樣本分佈

例子： 最大呼氣量 (Forced Expoiratory Volume in one second, FEV1) 用於測量一個人的肺功能，它的測量值是連續的。我們從前來門診的人中隨機抽取 $n$ 人作爲樣本，用這個樣本的 FEV1 平均值來估計這個診所的患者的平均肺功能。

**模型假設：** 在這個例子中，我們的假設有如下：每個隨機抽取的 FEV1 測量值都是從同一個總體（人羣）中抽取，每一個觀察值 $Y_i$ 都互相獨立互不影響。我們用縮寫 iid 表示這些隨機抽取的樣本是服從獨立同分佈 (independent and identically distributed)。另外，總體的分佈也假定爲正態分佈，且總體均值爲 $\mu$，總體方差爲 $\sigma^2$。那麼這個模型可以簡單的被寫成：

$$Y_i \stackrel{i.i.d}{\sim} N(\mu, \sigma^2), i=1,2,\dots,n$$

**總體均值 $\mu$ 的估計量：** 顯然算術平均值: $\bar{Y}=\frac{1}{n}\sum_{i=1}^ny_i$ 是我們用於估計總體均值的估計量。

**估計量的樣本分佈：**
$$\bar{Y}\stackrel{i.i.d}{\sim}N(\mu, \frac{\sigma^2}{n})$$

 **證明**

$$
\begin{aligned}
E(\bar{Y}) &= E(\frac{1}{n}\sum Y_i) \\
           &= \frac{1}{n}E(\sum Y_i) \\
           &= \frac{1}{n}\sum E(Y_i) \\
           &= \frac{1}{n}n\mu = \mu \\
Var(\bar{Y}) &= Var(\frac{1}{n}\sum Y_i) \\
\because Y_i \;are &\; independent   \\
            &= \frac{1}{n^2}\sum Var(Y_i) \\
            &= \frac{1}{n^2} n Var(Y_i) \\
            &= \frac{\sigma^2}{n}
\end{aligned}
$$

**證明當 $Z=\frac{\bar{Y}-\mu}{\sqrt{Var(\bar{Y})}}$ 時， $Z\sim N(0,1)$:**

由式子可知， $Z$ 只是由一組服從正態分佈的數據 $\bar{Y}$ 線性轉換 (linear transformation) 而來，所以 $Z$ 本身也服從正態分佈

$$
\begin{aligned}
E(Z) &= \frac{1}{\sqrt{Var(\bar{Y})}}E[\bar{Y}-\mu] \\
     &= \frac{1}{\sqrt{Var(\bar{Y})}}[\mu-\mu] = 0 \\
Var(Z) &= \frac{1}{Var(\bar{Y})}Var[\bar{Y}-\mu] \\
       &= \frac{1}{Var(\bar{Y})}Var(\bar{Y}) =1 \\
\therefore Z \;&\sim N(0,1)
\end{aligned}
$$

**均值 $\mu$ 的信賴區間：** 上節說道，

> 信賴區間通常是成對成對的出現的，即有上限和下限。這樣的一對從樣本數據中計算得來的統計量，同樣也是有樣本分佈的。**每次我們重新從總體或人羣中抽樣，計算獲得的信賴區間都不同，這些信賴區間就組成了信賴區間的樣本分佈。總體和人羣的參數落在這些信賴區間範圍內的概率，就是我們常說的信賴區間的水平（$95\%$）。** 常用的這個概率值就是 $95\%, 90\%, 99\%$。

假定我們用 $95\%$ 作爲信賴區間的水平。那麼下面我們嘗試推導一下信賴區間的計算公式。從長遠來說（也就是假設我們從總體中抽樣無數次，每次都進行信賴區間的計算，也獲得無數個信賴區間），這些信賴區間中有 $95\%$ 是包含了總體的真實均值（但是卻是未知）的，而且這些信賴區間由於是從一個服從正態分佈的數據而來，它們也服從正態分佈（對真實均值左右對稱）。所以我們有理由相信，可以找到一個數值 $c$：

$$Prob(\bar{Y} > \mu+c) = 0.025 \\
  Prob(\bar{Y} < \mu-c) = 0.025$$


因此，我們可以定義 $95\%$ 信賴區間的上限和下限分別是：

$$L=\bar{Y}-c \Rightarrow Prob(L>\mu)=0.025 \\
  U=\bar{Y}+c \Rightarrow Prob(U<\mu)=0.025$$


![](img/Selection_082.png)

接下來就是推倒（故意的）$c$ 的過程啦：

$$
\begin{aligned}
Prob(\bar{Y}>\mu+c)=Prob(\bar{Y}-\mu>c) \;&= 0.025 \\
\Rightarrow Prob(\frac{\bar{Y}-\mu}{\sqrt{Var(\bar{Y})}} > \frac{c}{\sqrt{Var(\bar{Y})}}) \;&= 0.025 \\
\Rightarrow Prob(Z>\frac{c}{\sqrt{Var(\bar{Y})}}) \;&= 0.025 \\
上面已經證明了 Z\sim N(0,1) \\
而且我們也已知 Prob(Z>1.96) \;&= 0.025 \\
所以只要令 \frac{c}{\sqrt{Var(\bar{Y})}} =1.96 \\
\Rightarrow c=1.96\sqrt{Var(\bar{Y})} \\
所以總體均值\mu 的 95\% 信賴區間就是: \\
\mu = \bar{Y}\pm1.96\sqrt{Var(\bar{Y})}=\bar{Y}\pm & 1.96\frac{\sigma}{\sqrt{n}}
\end{aligned}
$$

其中，$\sqrt{Var(\bar{Y})}$ 就是我們熟知的估計量 $\bar{Y}$ 的標準誤。



## 估計量的特質

考慮以下的問題：

1. 什麼因素決定了一個估計量 (estimator) 的好壞，是否實用？
2. 如果有其他的可選擇估計量，該如何取捨呢？
3. 當情況複雜的時候，我們該如何尋找合適的估計量？

### 偏倚

假設 $T$ 是我們估計總體參數 $\theta$ 的一個估計量。一般來說我們希望估計量的樣本分佈可以在 `“正確的位置”` 左右均勻分佈。換句話說我們希望：

$$E(T)=\theta$$

如果實現了這個條件，我們說這樣的估計量是無偏的 (`unbiased`)。然而，天下哪有這等好事，我們叫真實值和估計量之間的差距爲偏倚：

$$bias(T) = E(T)-\theta$$

其實偏倚完全等於零並不是最重要，許多常見的估計量都是有偏倚的。重要的是，這個偏倚會隨着樣本量的增加而逐漸趨近於零。所以我們就可以認爲這樣的估計量是漸進無偏的 (asymptotically unbiased)：

$$T\;is\;an\;\textbf{unbiased}\;estimator\;for\;\theta\;if\;\\E(T)=\theta\\
T\;is\;an\;\textbf{asymptotically unbiased}\;estimator\;for\;\theta\;if\;\\lim_{n\rightarrow\infty}E(T)=\theta$$

### 估計量的效能 Efficiency

通常，我們希望一個估計量 (estimator) 的偏倚要小，同時，它的樣本分佈也希望能儘可能的不要波動太大。換句話說，我們還希望估計量的方差越小越好。

如果說，兩個估計量有相同的偏倚，均可以選擇來推斷總體，我們說，其中樣本分佈的方差小的那個（波動幅度小）的那個估計量是相對更好的。因爲樣本分佈方差越小，說明可以**更加精確的**估計總體參數。這兩個估計量的方差之比：$Var(S)/Var(T)$ 被叫做這兩個估計量的**相對效能 (relative efficiency)**。所以我們用估計量去推斷總體時，需要選用效能最高，精確度最好的估計量 **(the minimum variance unbiased estimator/an efficient estimator)**。

### 均值和中位數的相對效能

在一個服從 $N(\mu,\sigma^2)$ 正態分佈的數據中，中位數和均值是一樣的，也都同時等於總體均值參數 $\mu$。而且，樣本均數 $\bar{Y}$ 和樣本中位數 $\dot{Y}$ 都是對總體均值的無偏估計量。那麼應該選用中位數還是平均值呢？

之前證明過當 $Y_i \sim N(\mu,\sigma^2)$ 時， $Var(\bar{Y}=\sigma^2/n)$。然而，當 $n$ 較大的時候，可以證明的是：

$$Var(\dot{Y})=\frac{\pi}{2}\frac{\sigma^2}{n}\approx1.571\frac{\sigma^2}{n}$$

因此，這兩個估計量的相對效能就是：

$$\frac{Var(\dot{Y})}{Var(\bar{Y})}\approx1.571$$

所以總體是正態分佈時，平均值就是較中位數更適合用來估計總體的估計量。


### 均方差 mean square error (MSE)

兩個估計量的偏倚不同時，可以比較他們和總體參數之間的差距，這被叫做均方差, Mean Square Error (MSE)。

$$MSE(T)=E[(T-\theta)^2]$$

這裏用一個數學技巧，將式子中的估計量和總體參數之間的差，分成兩個部分：一是估計量本身的方差 ($T-E(T)$)，一是估計量的偏倚 ($E(T)-\theta$)。

$$
\begin{aligned}
MSE(T) &= E[(T-\theta)^2] \\
       &= E\{[T-E(T)+E(T)-\theta]^2\} \\
       &= E\{[T-E(T)]^2+[E(T)-\theta]^2 \\
       & \;\;\;\;\; \;\;+2[T-E(T)][E(T)-\theta]\} \\
       &= E\{[T-E(T)]^2\}+E\{[E(T)-\theta]^2\} + 0\\
       &= Var(T) + [bias(T)^2]
\end{aligned}
$$

## 總體方差的估計，自由度

如果 $Y_i \sim (\mu, \sigma^2)$，並不需要默認或者假定它服從正態分佈或者任何分佈。那麼它的方差我們會用：

$$V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\mu)$$

**證明 $V_{\mu}$ 是 $\sigma^2$ 的無偏估計：**

$$
\begin{aligned}
V_{\mu} &= \frac{1}{n}\sum_{i=1}^n(Y_i-\mu) \\
需要證明 &E(V_{\mu}) = \sigma^2 \\
\Rightarrow E(V_{\mu}) &= \frac{1}{n}\sum_{i=1}^nE(Y_i-\mu)^2 \\
        &= \frac{1}{n}\sum_{i=1}^nVar(Y_i) \\
        &= \frac{1}{n}\sum_{i=1}^n\sigma^2 \\
        &= \sigma^2
\end{aligned}
$$

然而通常情況下，我們並不知道總體的均值 $\mu$。因此，只好用樣本的均值 $\bar{Y}$ 來估計 $\mu$。所以上面的方程就變成了：

$$V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})$$

你如果仔細觀察認真思考，就會發現，上面這個式子是`有問題的`。這個大問題就在於，$Y_i-\bar{Y}$ 中我們忽略掉了樣本均值 $\bar{Y}$ 和總體均值 $\mu$ 之間的差 ($\bar{Y}-\mu$)。因此上面的計算式來估計總體方差時，很顯然是會低估平均平方差，從而低估了總體方差。

這裏需要引入**自由度 (degree of freedom)** 在參數估計中的概念。

字面上可以理解爲：自由度是估計過程中使用了多少互相獨立的信息。所以在上面第一個公式中：$V_{\mu}=\frac{1}{n}\sum_{i=1}^n(Y_i-\mu)$。所有的 $n$ 個觀察值互相獨立，不僅如此，他們還對總體均值獨立。然而在第二個我們用 $\bar{Y}$ 取代了 $\mu$ 的公式中，樣本均數則與觀察值不互相獨立。因爲**樣本均數必然總是落在觀察值的中間**。然而總體均數並不一定就會落在觀察值中間。總體均數，和觀察值之間是自由，獨立的。因此，當我們觀察到 $n-1$ 個觀察值時，剩下的最後一個觀察值，決定了樣本均值的大小。所以說，樣本均值的自由度，是 $n-1$。

所以，加入了自由度的討論，我們可以相信，用樣本估計總體的方差時，使用下面的公式將會是總體方差的無偏估計：

$$V_{n-1}=\frac{1}{n-1}\sum_{i=1}^n(Y_i-\bar{Y})=\frac{n}{n-1}V_n$$


**證明**

利用上面也用到過的證明方法 -- 把樣本和總體均值之間的差分成兩部分：

$$
\begin{aligned}
V_{\mu} &= \frac{1}{n}\sum_{i=1}^n(Y_i-\mu)^2 \\
        &= \frac{1}{n}\sum_{i=1}^n[(Y_i-\bar{Y})+(\bar{Y}-\mu)]^2 \\
        &= \frac{1}{n}\sum_{i=1}^n[(Y_i-\bar{Y})^2+(\bar{Y}-\mu)^2\\
        &\;\;\;\;\;\;\;\;\;\;\;\;+2(Y_i-\bar{Y})(\bar{Y}-\mu)]\\
        &=\frac{1}{n}\sum_{i=1}^n(Y_i-\bar{Y})^2+\frac{1}{n}\sum_{i=1}^n(\bar{Y}-\mu)^2\\
        &\;\;\;\;\;\;\;\;\;\;\;\;+\frac{2}{n}(\bar{Y}-\mu)\sum_{i=1}^n(Y_i-\bar{Y}) \\
        &= V_n+(\bar{Y}-\mu)^2 \\ &\;\;\;\;\;\;\;\;\;\;\;\;(note\;that\;\sum_{i=1}^n(Y_i-\bar{Y})=0) \\
\Rightarrow  V_n &= V_{\mu}-(\bar{Y}-\mu)^2  \\
\therefore E(V_n)&= E(V_{\mu}) - E[(\bar{Y}-\mu)^2] \\
                 &= Var(Y)-Var(\bar{Y}) \\
                 &= \sigma^2-\frac{\sigma^2}{n} \\
                 &= \sigma^2(\frac{n-1}{n})
\end{aligned}
$$

因此，我們看見 $V_n$ 正如上面討論的那樣，是低估了總體方差的。雖然當 $n\rightarrow\infty$ 時無限接近 $\sigma^2$ 但是依然是低估了的。所以，我們可以對之進行修正：

$$
\begin{aligned}
E[\frac{n}{n-1}V_n]     &= \frac{n}{n-1}E[V_n] =\sigma^2 \\
\Rightarrow E[V_{n-1}]  &= \sigma^2
\end{aligned}
$$

## 樣本方差的樣本分佈

 $S^2$ 常用來標記樣本方差，取代上面我們用到的 $V_{n-1}$：

 $$S^2=\frac{1}{n-1}\sum_{i=1}^n(Y_i-\bar{Y})^2$$

而且上面也證明了，$E(S^2)=\sigma^2$ 是總體方差的無偏估計。然而，要注意的是，樣本標準差 $\sqrt{S^2}$ 卻不是總體標準差 $\sigma$ 的無偏估計（因爲並不是線性變換，而是開了根號）。

 **證明樣本標準差 $S$ 不是總體標準差 $\sigma$ 的無偏估計**

$$
\begin{aligned}
Var(S)               &=E(S^2)-[E(S)]^2 \\
\Rightarrow [E(S)]^2 &=E(S^2)-Var(S) \\
\because E(S^2)      &=\sigma^2 \\
\therefore   [E(S)]^2 &=\sigma^2-Var(S) \\
             E(S)     &=\sqrt{\sigma^2-Var(S)} \\
\end{aligned}$$

**可見樣本標準差是低估了總體標準差的。**

另外可以被證明的是：

$$\frac{n-1}{\sigma^2}S^2\sim \mathcal{X}_{n-1}^2\\
Var(S^2)=\frac{2\sigma^4}{n-1}$$

$\mathcal{X}^2_m$： 自由度爲 $m$ 的卡方分佈 (Section \@ref(chi-square-distribution))。是在圖形上向右歪曲的分佈。當自由度增加時，會越來越接近正態分佈。


# 卡方分佈 Chi-square distribution {#chi-square-distribution}

## 卡方分佈的期望和方差的證明


當 $X\sim N(0,1)$ 時， $X^2\sim \mathcal{X}_1^2$

如果 $X_1, \dots, X_n\stackrel{i.i.d}{\sim} N(0,1)$，
那麼 $\sum_{i=1}^nX_i^2\sim\mathcal{X}_n^2$

其中： $\mathcal{X}_n^2$ 表示自由度爲 $n$ 的卡方分佈。

且 $X_m^2+X_n^2=\mathcal{X}_{m+n}^2$

### 卡方分佈的期望

$$E(X_1^2)=Var(X)+[E(X)]^2=1+0=1$$

$$\Rightarrow E(X_n^2)=n$$


### 卡方分佈的方差

$$
\begin{aligned}
Var(X_1^2) &= E(X_1^{2^2}) - E(X_1^2)^2 \\
           &= E(X_1^4)-1
\end{aligned}
$$

#### 下面來求 $E(X_1^4)$

$$
\begin{aligned}
\because E(X_1) &= \int_{-\infty}^{+\infty} xf(x)dx \\
\therefore E(X_1^4) &= \int_{-\infty}^{+\infty} x^4f(x)dx
\end{aligned}$$

已知： $f(x)=\frac{1}{\sqrt{2\pi}}e^{(-\frac{x^2}{2})}$ 代入上式：

$$
\begin{aligned}
E(X_1^4) &= \int_{-\infty}^{+\infty} x^4f(x)dx \\
         &= \int_{-\infty}^{+\infty} x^4\frac{1}{\sqrt{2\pi}}e^{(-\frac{x^2}{2})}dx\\
         &=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^4e^{(-\frac{x^2}{2})}dx\\
         &=\frac{-1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^3(-x)e^{(-\frac{x^2}{2})}dx
\end{aligned}
$$

令 $u=x^3, v=e^{(-\frac{x^2}{2})},t=-\frac{x^2}{2}$
可以推導：

$$
\begin{aligned}
\frac{dv}{dx} &= \frac{dv}{dt}\frac{dt}{dx} \\
              &= e^t(-\frac{1}{2}\times2x) \\
              &= (-x)e^{(-\frac{x^2}{2})} \\
\Rightarrow dv &= (-x)e^{(-\frac{x^2}{2})}dx
\end{aligned}
$$

再代入上面的式子：


$$
\begin{aligned}
E(X_1^4) &= \frac{-1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}u\:dv \\
integrate\; &by\; parts:\\
E(X_1^4) &= \frac{-1}{\sqrt{2\pi}}\{[u\:v] \rvert_{-\infty}^{+\infty}-\int_{-\infty}^{+\infty}v\:du\} \\
&= \frac{-1}{\sqrt{2\pi}}\{[x^3e^{(-\frac{x^2}{2})}]\rvert_{-\infty}^{+\infty} -\int_{-\infty}^{+\infty}v\:du\} \\
&=\frac{-1}{\sqrt{2\pi}}\{0-0-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx^3\} \\
&=\frac{-1}{\sqrt{2\pi}}[-3\int_{-\infty}^{+\infty}x^2e^{(-\frac{x^2}{2})}dx] \\
&=\frac{-3}{\sqrt{2\pi}}[\int_{-\infty}^{+\infty}x(-x)e^{(-\frac{x^2}{2})}dx] \\
\end{aligned}
$$

再來一次分部積分：

令 $a=x,b=e^{(-\frac{x^2}{2})},d\:b = (-x)e^{(-\frac{x^2}{2})}dx$

$$
\begin{aligned}
E(X_1^4) &= \frac{-3}{\sqrt{2\pi}}\{[a\:b] \rvert_{-\infty}^{+\infty} - \int_{-\infty}^{+\infty}b\:da\} \\
&=\frac{-3}{\sqrt{2\pi}}\{[xe^{(-\frac{x^2}{2})}]\rvert_{-\infty}^{+\infty} -\int_{-\infty}^{+\infty}b\:da\} \\
&=\frac{-3}{\sqrt{2\pi}}\{0-0-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx\} \\
&=\frac{-3}{\sqrt{2\pi}}[-\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx] \\
&=\frac{3}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx
\end{aligned}
$$

下面令 $I=\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx\\
\Rightarrow I^2=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{(-\frac{x^2+y^2}{2})}dxdy$

接下來需要用到 [座標轉換](https://www.youtube.com/watch?v=r0fv9V9GHdo)的知識，將 $x,y$ 表示的笛卡爾座標，轉換爲用角度 $\theta$ 和半徑 $r$ 表示的形式。之後的證明可以在[油管](https://www.youtube.com/watch?v=fWOGfzC3IeY)上看到，但是我還是繼續證明下去。


直角座標系 (cartesian coordinators) 和
極座標系 (polar coordinators) 之間轉換的關係如下：


$$
\begin{aligned}
x&=r\:cos\theta\\
y&=r\:sin\theta\\
r^2&=x^2+y^2\\
\end{aligned}
$$

座標轉換以後可以繼續求 $E(X_1^4)$。 在那之前我們先求 $I^2$。
注意轉換座標系統以後，$\theta\in[0,2\pi], r\in[0,+\infty]$

$$
\begin{aligned}
I^2 &= \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{(-\frac{x^2+y^2}{2})}dxdy \\
&= \int_{0}^{+\infty}\int_{0}^{2\pi}e^{(-\frac{r^2}{2})}rd\theta dr \\
\end{aligned}
$$

由於先從中間的 $\int_{0}^{2\pi}e^{(-\frac{r^2}{2})}rd\theta$ 開始積分，$\theta$ 以外都可以視爲常數，那麼這個 $[0,2\pi]$ 上的積分就的等於 $2\pi e^{(-\frac{r^2}{2})}r$。

因此上面的式子又變爲：


$$
\begin{aligned}
I^2 &=  2\pi\int_{0}^{+\infty}e^{(-\frac{r^2}{2})}r\:dr \\
\because \frac{d(e^{\frac{-r^2}{2}})}{dr} &= -e^{(-\frac{r^2}{2})}r \\
\therefore I^2 &= 2\pi(-e^{\frac{-r^2}{2}})\rvert_0^{+\infty} \\
               &= 0-(2\pi\times(-1)) \\
               &= 2\pi\\
\Rightarrow I  &= \sqrt{2\pi}
\end{aligned}
$$

所以，


$$
\begin{aligned}
E(X_1^4) &= \frac{3}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{(-\frac{x^2}{2})}dx \\
&= \frac{3}{\sqrt{2\pi}}\times I \\
&= 3 \\
\Rightarrow Var(X_1^2) &= E(X_1^4) - 1 \\
                       &= 3-1 =2 \\
\Rightarrow Var(X_n^2) &= 2n
\end{aligned}
$$


結論：$X_1, \dots, X_n\stackrel{i.i.d}{\sim} N(0,1)$ 時，$\sum_{i=1}^nX_i^2\sim\mathcal{X}_n^2$ 服從卡方分佈，其期望 $E(X_n^2)=n$，方差 $Var(X_n^2)=2n$。
根據[中心極限定理](https://winterwang.github.io/post/central-limit-theory/)

$$n\rightarrow \infty, X_n^2\sim N(n, 2n)$$
